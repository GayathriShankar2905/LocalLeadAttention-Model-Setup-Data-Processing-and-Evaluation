# -*- coding: utf-8 -*-
"""INITIAL WORK CARDIOLYSE.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1R701U2xEAvco00mway4MxGUAwV4rFbwM
"""

# Commented out IPython magic to ensure Python compatibility.
!git clone https://github.com/cph-cachet/LocalLeadAttention.git
# %cd LocalLeadAttention

!pip install numpy scipy scikit-learn joblib pandas tabulate tqdm scikit-multilearn

def load_challenge_data(filename):
    # Example: Loading ECG signals and metadata
    with open(filename, 'r') as f:
        # Parse data and return signals, labels, etc.
        data = f.read()
    return data

import os
import requests
from concurrent.futures import ThreadPoolExecutor

# ‚úÖ Base URL for the MIT-BIH Arrhythmia Database
BASE_URL = "https://physionet.org/files/mitdb/1.0.0/"

# ‚úÖ Directory to save downloaded files
SAVE_DIR = "./mitdb/records/"
os.makedirs(SAVE_DIR, exist_ok=True)

# ‚úÖ URL of the RECORDS file (list of all record names)
records_file_url = BASE_URL + "RECORDS"
records_file_path = os.path.join(SAVE_DIR, "RECORDS")

# ‚úÖ Download the RECORDS file if it doesn't already exist
if not os.path.exists(records_file_path):
    print("üì• Downloading RECORDS file...")
    response = requests.get(records_file_url)
    response.raise_for_status()
    with open(records_file_path, "w") as f:
        f.write(response.text)
    print("‚úÖ RECORDS file downloaded!")

# ‚úÖ Read the list of valid records from the RECORDS file
with open(records_file_path, "r") as f:
    valid_records = [line.strip() for line in f.readlines()]

# ‚úÖ Choose the first 20 records
selected_records = valid_records[:20]  # First 20 records

# ‚úÖ Function to download .dat, .hea, and .atr files for a record
def download_record(record_name):
    """Download .dat, .hea, and .atr files for the given record."""
    for ext in [".dat", ".hea", ".atr"]:
        file_url = f"{BASE_URL}{record_name}{ext}"
        file_path = os.path.join(SAVE_DIR, f"{record_name}{ext}")

        # Skip download if the file already exists
        if os.path.exists(file_path):
            print(f"‚úÖ Already downloaded: {record_name}{ext}")
            continue

        try:
            response = requests.get(file_url, stream=True)
            response.raise_for_status()
            with open(file_path, "wb") as file:
                for chunk in response.iter_content(chunk_size=1024):
                    file.write(chunk)
            print(f"‚úÖ Successfully downloaded: {record_name}{ext}")
        except requests.exceptions.RequestException as e:
            print(f"‚ùå Failed to download {record_name}{ext}: {e}")

# ‚úÖ Use multi-threading to download selected records
with ThreadPoolExecutor(max_workers=5) as executor:
    executor.map(download_record, selected_records)

print("‚úÖ Download process completed!")

!pip install wfdb

import wfdb

# Example: Load a record
record = wfdb.rdrecord("./mitdb/records/100")
signal = record.p_signal  # ECG signal
print("Signal shape:", signal.shape)  # Typically [N_samples, N_leads]

from scipy.signal import resample

def resample_signal(signal, original_rate=360, target_rate=500):
    """Resample the signal to the desired rate."""
    num_samples = int(signal.shape[0] * target_rate / original_rate)
    resampled_signal = resample(signal, num_samples, axis=0)  # Resample along the time axis
    return resampled_signal

# Example
resampled_signal = resample_signal(signal, original_rate=360, target_rate=500)
print("Resampled shape:", resampled_signal.shape)

def normalize_signal(signal):
    """Normalize each lead (channel) independently."""
    normalized_signal = (signal - signal.mean(axis=0)) / signal.std(axis=0)
    return normalized_signal

# Example
normalized_signal = normalize_signal(resampled_signal)  # Apply to resampled signal
print("Normalized shape:", normalized_signal.shape)

import numpy as np

def segment_signal(signal, window_size=1800, step_size=1800):
    """Segment the signal into overlapping/non-overlapping windows."""
    segments = []
    for start in range(0, signal.shape[0] - window_size + 1, step_size):
        segments.append(signal[start:start + window_size])
    return np.array(segments)

# Example
window_size = 1800  # 5 seconds at 360 Hz
segments = segment_signal(normalized_signal, window_size=window_size, step_size=window_size)
print("Segments shape:", segments.shape)  # Expected: (num_windows, 1800, 2)

# Load annotations
annotation = wfdb.rdann("./mitdb/records/100", "atr")

# Extract sample indices and labels
sample_indices = annotation.sample
labels = annotation.symbol
print("Annotations:", list(zip(sample_indices, labels)))

unique_labels = set(labels)  # labels from annotation.symbol
print("Unique labels:", unique_labels)
num_classes = len(unique_labels)

# Map labels to integers
label_mapping = {'N': 0, 'V': 1, 'A': 2, '+': 3}
numerical_labels = [label_mapping[label] for label in labels]

print("Numerical Labels:", numerical_labels)

label_mapping = {'N': 0, 'V': 1, 'A': 2, '+': 3}
segment_labels_int = np.array(segment_labels, dtype=np.int64)  # ‚úÖ Directly convert to NumPy array

print("First 10 segment labels:", segment_labels[:10])
print("Type of first label:", type(segment_labels[0]))

from imblearn.over_sampling import RandomOverSampler
import numpy as np

# Convert to NumPy array (already integers, so no mapping needed)
segment_labels_int = np.array(segment_labels, dtype=np.int64)

# Apply oversampling
oversampler = RandomOverSampler(sampling_strategy="auto", random_state=42)
segments_resampled, labels_resampled = oversampler.fit_resample(segments, segment_labels_int)

# Print new class distribution
unique, counts = np.unique(labels_resampled, return_counts=True)
print("New balanced class distribution:", dict(zip(unique, counts)))

from imblearn.over_sampling import RandomOverSampler
import numpy as np

# Convert labels to numpy array
segment_labels_int = np.array([label_mapping[label] for label in segment_labels])

# Apply oversampling
oversampler = RandomOverSampler(sampling_strategy="auto", random_state=42)
segments_resampled, labels_resampled = oversampler.fit_resample(segments, segment_labels_int)

# Print new class distribution
unique, counts = np.unique(labels_resampled, return_counts=True)
print("New balanced class distribution:", dict(zip(unique, counts)))

num_classes = 4  # 'N', 'V', 'A', '+'

import numpy as np

unique, counts = np.unique(segment_labels, return_counts=True)
print("Class distribution:", dict(zip(unique, counts)))

def load_mitdb_data(data_dir):
    # Load preprocessed data (signals and labels)
    signals = np.load(os.path.join(data_dir, "signals.npy"))
    labels = np.load(os.path.join(data_dir, "labels.npy"))
    return signals, labels

import torch
import torch.nn as nn
import torch.nn.functional as F

class LocalLeadAttention(nn.Module):
    def __init__(self, input_size, num_classes, num_leads=2, hidden_size=256, num_heads=4, dropout_rate=0.3):
        """
        LocalLeadAttention model for multi-lead ECG classification.

        Args:
            input_size (int): Length of the input signal (e.g., 1800 time steps).
            num_classes (int): Number of output classes (e.g., 4).
            num_leads (int): Number of input channels/leads (e.g., 2).
            hidden_size (int): Size of the hidden layers.
            num_heads (int): Number of attention heads.
            dropout_rate (float): Dropout rate for regularization.
        """
        super(LocalLeadAttention, self).__init__()
        self.num_heads = num_heads
        self.hidden_size = hidden_size

        # Input layer for each lead
        self.input_layer = nn.Conv1d(
            in_channels=num_leads,
            out_channels=hidden_size,
            kernel_size=5,
            stride=1,
            padding=2
        )
        self.norm1 = nn.LayerNorm(hidden_size)
        self.dropout = nn.Dropout(dropout_rate)

        # Multi-head attention
        self.attention = nn.MultiheadAttention(
            embed_dim=hidden_size,
            num_heads=num_heads,
            batch_first=True
        )
        self.norm2 = nn.LayerNorm(hidden_size)

        # Fully connected layers
        self.fc1 = nn.Linear(hidden_size, 64)
        self.fc2 = nn.Linear(64, num_classes)

    def forward(self, x):
        """
        Forward pass of the LocalLeadAttention model.

        Args:
            x (torch.Tensor): Input tensor of shape (batch_size, time_steps, num_leads).

        Returns:
            torch.Tensor: Output logits of shape (batch_size, num_classes).
        """
        # Reshape input for Conv1d: (batch_size, num_leads, time_steps)
        x = x.permute(0, 2, 1)  # Shape: (batch_size, num_leads, time_steps)

        # Apply convolution to extract features
        x = self.input_layer(x)  # Shape: (batch_size, hidden_size, time_steps)
        x = self.dropout(self.norm1(x.permute(0, 2, 1)))  # Normalize and apply dropout
        x = x.permute(0, 2, 1)  # Shape: (batch_size, time_steps, hidden_size)

        # Apply multi-head attention
        attn_output, _ = self.attention(x, x, x)  # Self-attention
        x = self.norm2(attn_output + x)  # Add residual connection and normalize

        # Global average pooling over time
        x = x.mean(dim=1)  # Shape: (batch_size, hidden_size)

        # Fully connected layers
        x = F.relu(self.fc1(x))
        x = self.fc2(x)  # Shape: (batch_size, num_classes)

        return x

# Define model parameters
input_size = 1800  # Signal length per segment
num_leads = 2      # Number of ECG leads (channels)
num_classes = 4    # Number of output classes ('N', 'A', '+', 'V')

# Initialize the model
model = LocalLeadAttention(
    input_size=input_size,
    num_leads=num_leads,
    num_classes=num_classes
)

# Print the model architecture
print(model)

input_size = 1800  # Length of each segment
num_classes = 4    # Number of classes: 'N', 'V', 'A', '+'

model = LocalLeadAttention(input_size=input_size, num_classes=num_classes)

print("Length of sample_indices:", len(sample_indices))
print("Length of labels:", len(labels))
print("First 10 sample_indices:", sample_indices[:10])
print("First 10 labels:", labels[:10])

# Filter sample_indices to ensure they're within bounds
valid_indices = [i for i in range(len(sample_indices)) if sample_indices[i] < len(labels)]
sample_indices = [sample_indices[i] for i in valid_indices]
labels = [labels[i] for i in valid_indices]

for i in range(len(segments)):
    # Define the range for the current segment
    segment_start = i * 1800
    segment_end = (i + 1) * 1800

    # Find all annotations within this range
    labels_in_segment = [
        labels[j] for j in range(len(sample_indices))
        if segment_start <= sample_indices[j] < segment_end and j < len(labels)
    ]

    # Assign the most frequent label in this segment
    if labels_in_segment:
        most_frequent_label = Counter(labels_in_segment).most_common(1)[0][0]
    else:
        most_frequent_label = "N"  # Assign "N" (normal) if no label exists in the segment

    segment_labels.append(most_frequent_label)

print("Shape of segments:", np.array(segments).shape)

import numpy as np
from collections import Counter

# Initialize the labels for each segment
segment_labels = []

for i in range(len(segments)):
    # Define the range for the current segment
    segment_start = i * 1800
    segment_end = (i + 1) * 1800

    # Find all annotations within this range
    labels_in_segment = [
        labels[j] for j in range(len(sample_indices))
        if segment_start <= sample_indices[j] < segment_end and j < len(labels)
    ]

    # Assign the most frequent label in this segment
    if labels_in_segment:
        most_frequent_label = Counter(labels_in_segment).most_common(1)[0][0]
    else:
        most_frequent_label = "N"  # Assign "N" (normal) if no label exists in the segment

    segment_labels.append(most_frequent_label)

# Check the result
print("Number of segments:", len(segments))
print("Number of segment labels:", len(segment_labels))
print("Unique labels in segments:", set(segment_labels))

import torch
import torch.nn as nn
import torch.nn.functional as F

class LocalLeadAttention(nn.Module):
    def __init__(self, input_size, num_classes, num_leads=2, hidden_size=128, num_heads=4):
        super(LocalLeadAttention, self).__init__()
        self.num_heads = num_heads
        self.hidden_size = hidden_size

        # Input layer for each lead
        self.input_layer = nn.Conv1d(in_channels=num_leads, out_channels=hidden_size, kernel_size=5, stride=1, padding=2)

        # Multi-head attention
        self.attention = nn.MultiheadAttention(embed_dim=hidden_size, num_heads=num_heads, batch_first=True)

        # Fully connected layers
        self.fc1 = nn.Linear(hidden_size, 64)
        self.fc2 = nn.Linear(64, num_classes)

    def forward(self, x):
        x = x.permute(0, 2, 1)  # Reshape for Conv1d: (batch_size, num_leads, time_steps)
        x = self.input_layer(x)  # Apply convolution
        x = x.permute(0, 2, 1)  # Reshape for attention: (batch_size, time_steps, hidden_size)
        attn_output, _ = self.attention(x, x, x)  # Self-attention
        x = attn_output + x  # Residual connection
        x = x.mean(dim=1)  # Global average pooling over time
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# Define model parameters
input_size = 1800  # Signal length per segment
num_leads = 2      # Number of ECG leads (channels)
num_classes = 4    # Number of output classes ('N', 'A', '+', 'V')

# Initialize the model
model = LocalLeadAttention(
    input_size=input_size,
    num_leads=num_leads,
    num_classes=num_classes
)

# Print the model architecture
print(model)

label_mapping = {'N': 0, 'V': 1, 'A': 2, '+': 3}  # Convert class labels to integers

segment_labels = [label_mapping[label] for label in segment_labels]

from torch.utils.data import Dataset, DataLoader
import numpy as np
import torch

class ECGDataset(Dataset):
    def __init__(self, signals, labels):
        self.signals = torch.tensor(signals, dtype=torch.float32)
        self.labels = torch.tensor(labels, dtype=torch.long)  # Classification labels

    def __len__(self):
        return len(self.signals)

    def __getitem__(self, idx):
        return self.signals[idx], self.labels[idx]

# Load preprocessed signals and labels
signals, labels = np.array(segments), np.array(segment_labels)  # Ensure correct shape

# Split into train and test sets
split_ratio = 0.8  # 80% training, 20% validation
split_idx = int(len(signals) * split_ratio)
train_signals, test_signals = signals[:split_idx], signals[split_idx:]
train_labels, test_labels = labels[:split_idx], labels[split_idx:]

train_dataset = ECGDataset(train_signals, np.array(train_labels, dtype=np.int64))
test_dataset = ECGDataset(test_signals, np.array(test_labels, dtype=np.int64))

# Define DataLoader
batch_size = 32  # Adjust as needed
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

import torch
import torch.nn as nn
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score

# Define training parameters
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = model.to(device)

# Define optimizer and loss functions
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
mse_loss = nn.MSELoss()

# Define Dice Loss
class DiceLoss(nn.Module):
    def __init__(self):
        super(DiceLoss, self).__init__()

    def forward(self, outputs, targets):
        smooth = 1e-5
        outputs = torch.sigmoid(outputs)  # Apply sigmoid if needed
        intersection = (outputs * targets).sum(dim=1)
        dice = (2. * intersection + smooth) / (outputs.sum(dim=1) + targets.sum(dim=1) + smooth)
        return 1 - dice.mean()

dice_loss = DiceLoss()

# Combine losses
def combined_loss(outputs, targets):
    mse = mse_loss(outputs, targets.float())
    dice = dice_loss(outputs, targets.float())
    return mse + dice

# Track metrics
train_losses, val_losses, val_accuracies = [], [], []

# Training loop
num_epochs = 10
for epoch in range(num_epochs):
    model.train()
    total_train_loss = 0

    for inputs, labels in train_loader:
        inputs, labels = inputs.to(device), labels.to(device)

        # One-hot encode labels for MSE and Dice Loss
        labels_onehot = torch.zeros(labels.size(0), num_classes).to(device)
        labels_onehot.scatter_(1, labels.unsqueeze(1), 1)

        # Zero the gradient
        optimizer.zero_grad()

        # Forward pass
        outputs = model(inputs)
        loss = combined_loss(outputs, labels_onehot)

        # Backward pass and optimization
        loss.backward()
        optimizer.step()

        total_train_loss += loss.item()

    train_losses.append(total_train_loss / len(train_loader))

    # Validation
    model.eval()
    total_val_loss = 0
    all_preds, all_labels = [], []

    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            # One-hot encode labels for validation
            labels_onehot = torch.zeros(labels.size(0), num_classes).to(device)
            labels_onehot.scatter_(1, labels.unsqueeze(1), 1)

            # Forward pass
            outputs = model(inputs)
            loss = combined_loss(outputs, labels_onehot)
            total_val_loss += loss.item()

            preds = torch.argmax(outputs, dim=1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    val_losses.append(total_val_loss / len(test_loader))
    val_accuracies.append(accuracy_score(all_labels, all_preds))

    print(f"Epoch [{epoch+1}/{num_epochs}], "
          f"Train Loss: {train_losses[-1]:.4f}, "
          f"Val Loss: {val_losses[-1]:.4f}, "
          f"Val Accuracy: {val_accuracies[-1]:.4f}")

# Plot training and validation losses
plt.figure(figsize=(10, 5))
plt.plot(range(1, num_epochs+1), train_losses, label='Train Loss')
plt.plot(range(1, num_epochs+1), val_losses, label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()

# Plot validation accuracy
plt.figure(figsize=(10, 5))
plt.plot(range(1, num_epochs+1), val_accuracies, label='Validation Accuracy', color='green')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Validation Accuracy')
plt.legend()
plt.show()

import torch
import numpy as np
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

def evaluate_model(model, val_loader):
    model.eval()  # Set to evaluation mode
    all_preds = []
    all_labels = []

    with torch.no_grad():  # No gradients needed
        for signals, labels in val_loader:
            signals, labels = signals.to(device), labels.to(device)

            outputs = model(signals)  # Model prediction

            # Convert logits to class predictions (multi-class)
            preds = torch.argmax(outputs, dim=1)  # Get the class with highest probability

            all_preds.extend(preds.cpu().numpy())  # Store predictions
            all_labels.extend(labels.cpu().numpy())  # Store true labels

    # Compute metrics
    accuracy = accuracy_score(all_labels, all_preds)
    precision = precision_score(all_labels, all_preds, average='macro', zero_division=0)
    recall = recall_score(all_labels, all_preds, average='macro', zero_division=0)
    f1 = f1_score(all_labels, all_preds, average='macro', zero_division=0)

    # Print evaluation results
    print(f"\nüìä Validation Results:")
    print(f"‚úÖ Accuracy:  {accuracy:.4f}")
    print(f"‚úÖ Precision: {precision:.4f}")
    print(f"‚úÖ Recall:    {recall:.4f}")
    print(f"‚úÖ F1-score:  {f1:.4f}")

# Run the evaluation
evaluate_model(model, test_loader)

import matplotlib.pyplot as plt

plt.plot(train_losses, label="Train Loss")
plt.plot(val_losses, label="Validation Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend()
plt.title("Training vs Validation Loss")
plt.show()

import torch

def check_validation_samples(model, val_loader, num_samples=10):
    model.eval()  # Set model to evaluation mode
    samples_checked = 0

    with torch.no_grad():  # No need for gradients during evaluation
        for signals, labels in val_loader:
            signals, labels = signals.to(device), labels.to(device)

            outputs = model(signals)
            preds = torch.argmax(outputs, dim=1)  # Get predicted class

            for i in range(len(labels)):
                print(f"‚úÖ True: {labels[i].item()} | üîÆ Predicted: {preds[i].item()}")
                samples_checked += 1
                if samples_checked >= num_samples:
                    return  # Stop after printing `num_samples`

# Run the function
check_validation_samples(model, test_loader, num_samples=10)

import numpy as np
unique, counts = np.unique(segment_labels, return_counts=True)
print("Class distribution in dataset:", dict(zip(unique, counts)))

unique, counts = np.unique(segment_labels, return_counts=True)
print("Class distribution:", dict(zip(unique, counts)))

